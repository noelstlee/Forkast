__pycache__/
*.py[cod]
*$py.class
*.so
.Python
*.egg
*.egg-info/
dist/
build/
*.pyc
dva_env/
venv/
env/
ENV/
.venv
.ipynb_checkpoints
*/.ipynb_checkpoints/*
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

data/raw/meta-Georgia.json
data/raw/review-Georgia.json

# LSTM data - ignore intermediate files, keep only training files (118 MB vs 374 MB)

team15proposal.pdf
*.log
.DS_Store
Thumbs.db
docs/

DATA_REBALANCING_SUMMARY.md
LSTM_PREDICTIONS_EXPLAINED.md
QUICK_START_TRANSFORMER.md
TRANSFORMER_SETUP_GUIDE.md

data/processed/*
data/raw/*

models/*

notebooks/transformer_business_training.ipynb
prediction_example.txt
src/data/lstm_preprocessing_transformer.py

src/data/verify_rebalanced_data.py
src/utils/practical_metrics.py

outputs/atlanta_business_predictions_with_meta.csv
outputs/atlanta_xgboost_predictions_with_meta.csv
outputs/meta-Georgia.json

data/processed/predictions_cache/

image/
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
*.egg
*.egg-info/
dist/
build/
*.pyc
dva_env/
venv/
env/
ENV/
.venv
.ipynb_checkpoints
*/.ipynb_checkpoints/*
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# But still ignore raw data (too large even for LFS)
data/raw/*.json.gz

# Cache artifacts
data/processed/ga/cache/

team15proposal.pdf
*.log
.DS_Store
Thumbs.db
docs/