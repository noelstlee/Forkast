# LSTM Training Guide for PACE ICE Cluster

This guide explains how to train the LSTM models on Georgia Tech's PACE ICE cluster with GPU access.

## Table of Contents
1. [Prerequisites](#prerequisites)
2. [Data Preparation](#data-preparation)
3. [Environment Setup on VM](#environment-setup-on-vm)
4. [Training the Models](#training-the-models)
5. [Monitoring Training](#monitoring-training)
6. [Retrieving Results](#retrieving-results)
7. [Troubleshooting](#troubleshooting)

---

## Prerequisites

### Local Machine (Already Completed)
- âœ… Preprocessing pipeline executed (`preprocess_lstm_atlanta.py`)
- âœ… LSTM data generated in `data/processed/ga/lstm_data/`
- âœ… Training notebooks created in `notebooks/`

### PACE ICE Cluster Access
- Georgia Tech account with PACE access
- SSH access to `login-ice.pace.gatech.edu`
- GPU allocation (request via PACE portal)

---

## Data Preparation

### 1. Commit and Push LSTM Data

The `.gitignore` has been configured to track LSTM data for Git:

```bash
# On your local machine
cd /path/to/Forkast
git add data/processed/ga/lstm_data/
git add notebooks/lstm_*_training.ipynb
git add preprocess_lstm_atlanta.py
git add src/data/split_data_atlanta.py
git add requirements.txt
git commit -m "Add LSTM preprocessing and training notebooks with Atlanta-specific splitting"
git push origin main
```

### 2. Verify Data Files

Ensure these files are committed (total ~118 MB, optimized for training only):

```
data/processed/ga/lstm_data/
â”œâ”€â”€ business_train.parquet           (18 MB)  âœ… Needed for training
â”œâ”€â”€ business_val.parquet             (7 MB)   âœ… Needed for training
â”œâ”€â”€ business_test.parquet            (32 MB)  âœ… Needed for training
â”œâ”€â”€ category_train.parquet           (16 MB)  âœ… Needed for training
â”œâ”€â”€ category_val.parquet             (7 MB)   âœ… Needed for training
â”œâ”€â”€ category_test.parquet            (38 MB)  âœ… Needed for training
â”œâ”€â”€ business_vocab.json              (963 KB) âœ… Needed for training
â”œâ”€â”€ category_vocab.json              (0.4 KB) âœ… Needed for training
â””â”€â”€ category_class_weights.json      (0.7 KB) âœ… Needed for training
```

**Note**: Intermediate files (train/val/test.parquet, atlanta_business_ids.json, biz_ga.parquet) 
are not tracked in Git as they're not needed for training. They can be regenerated by running 
`preprocess_lstm_atlanta.py` if needed.

---

## Environment Setup on VM

### 1. Login to PACE ICE

```bash
ssh <your_gt_username>@login-ice.pace.gatech.edu
```

### 2. Request Interactive GPU Session

```bash
# Request 1 GPU for 4 hours (adjust as needed)
salloc --gres=gpu:1 --mem=32G --time=4:00:00 --ntasks=4

# Once allocated, note the node name (e.g., ice-node-01)
# SSH into the allocated node
ssh ice-node-XX  # Replace XX with your allocated node
```

### 3. Clone Repository

```bash
cd $HOME
git clone https://github.com/your-username/Forkast.git
cd Forkast
```

### 4. Setup Python Environment

```bash
# Load CUDA module (check available versions with `module avail cuda`)
module load cuda/11.8

# Create virtual environment
python3 -m venv lstm_env
source lstm_env/bin/activate

# Upgrade pip
pip install --upgrade pip

# Install PyTorch with CUDA support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
pip install -r requirements.txt
```

### 5. Verify GPU Access

```python
python3 << EOF
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'GPU device: {torch.cuda.get_device_name(0)}')
    print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')
else:
    print('âš ï¸  WARNING: CUDA not available!')
EOF
```

Expected output:
```
PyTorch version: 2.x.x
CUDA available: True
CUDA version: 11.8
GPU device: NVIDIA A100-SXM4-40GB (or similar)
GPU memory: 40.00 GB
```

---

## Training the Models

### Option 1: Interactive Jupyter Notebook (Recommended for Development)

```bash
# Start Jupyter Lab
jupyter lab --no-browser --port=8888

# On your local machine, create SSH tunnel:
ssh -L 8888:localhost:8888 <username>@ice-node-XX

# Open browser: http://localhost:8888
# Navigate to notebooks/ and run:
#   - lstm_business_training.ipynb
#   - lstm_category_training.ipynb
```

### Option 2: Command-Line Execution (Recommended for Production)

Convert notebooks to Python scripts:

```bash
# Convert notebooks to scripts
jupyter nbconvert --to script notebooks/lstm_business_training.ipynb
jupyter nbconvert --to script notebooks/lstm_category_training.ipynb

# Run training
python3 notebooks/lstm_business_training.py > logs/business_training.log 2>&1 &
python3 notebooks/lstm_category_training.py > logs/category_training.log 2>&1 &
```

### Option 3: SLURM Batch Job (Recommended for Long Training)

Create `train_business_lstm.sh`:

```bash
#!/bin/bash
#SBATCH --job-name=business_lstm
#SBATCH --output=logs/business_lstm_%j.out
#SBATCH --error=logs/business_lstm_%j.err
#SBATCH --gres=gpu:1
#SBATCH --mem=32G
#SBATCH --time=8:00:00
#SBATCH --ntasks=4

# Load modules
module load cuda/11.8

# Activate environment
source $HOME/Forkast/lstm_env/bin/activate

# Run training
cd $HOME/Forkast
python3 -c "
import sys
sys.path.insert(0, '.')
exec(open('notebooks/lstm_business_training.ipynb').read())
"
```

Submit job:
```bash
sbatch train_business_lstm.sh
```

---

## Monitoring Training

### Check GPU Usage

```bash
# Real-time GPU monitoring
watch -n 1 nvidia-smi

# Or
gpustat -i 1
```

### Monitor Training Logs

```bash
# For interactive runs
tail -f logs/business_training.log

# For SLURM jobs
tail -f logs/business_lstm_<job_id>.out
```

### Check Training Progress

Training notebooks save:
- **Checkpoints**: `models/business_lstm/best_model.pt`
- **Training curves**: `models/business_lstm/training_history.png`
- **Predictions**: `data/processed/ga/lstm_data/atlanta_business_predictions.parquet`

---

## Retrieving Results

### 1. Download Model Checkpoints

```bash
# On your local machine
scp -r <username>@login-ice.pace.gatech.edu:~/Forkast/models/ ./models/
```

### 2. Download Predictions

```bash
scp <username>@login-ice.pace.gatech.edu:~/Forkast/data/processed/ga/lstm_data/*predictions.parquet \
    ./data/processed/ga/lstm_data/
```

### 3. Download Training Logs

```bash
scp -r <username>@login-ice.pace.gatech.edu:~/Forkast/logs/ ./logs/
```

---

## Training Configuration

### Business LSTM
- **Vocabulary**: 19,979 businesses (top-20K + PAD + UNK)
- **Embedding dim**: 128
- **Hidden dim**: 256
- **Num layers**: 2
- **Dropout**: 0.3
- **Batch size**: 512
- **Learning rate**: 0.001
- **Max epochs**: 50
- **Early stopping**: 5 epochs patience
- **Loss**: CrossEntropyLoss
- **Data split**: 
  - Train: 1.86M examples (non-Atlanta users)
  - Val: 987K examples (non-Atlanta users)
  - Test: 4.95M examples (Atlanta users only)

### Category LSTM
- **Vocabulary**: 26 categories
- **Embedding dim**: 128
- **Hidden dim**: 256
- **Num layers**: 2
- **Dropout**: 0.3
- **Batch size**: 512
- **Learning rate**: 0.001
- **Max epochs**: 50
- **Early stopping**: 5 epochs patience
- **Loss**: **Weighted** CrossEntropyLoss (handles 140:1 imbalance)
- **Data split**: Same as business (no Atlanta filtering for categories)

### Expected Training Time
- **Business LSTM**: ~2-3 hours on A100 GPU
- **Category LSTM**: ~2-3 hours on A100 GPU
- **Total**: ~4-6 hours for both models

---

## Troubleshooting

### Issue: CUDA Out of Memory

**Solution**: Reduce batch size in notebooks:
```python
BATCH_SIZE = 256  # Instead of 512
```

### Issue: Slow Training on CPU

**Verify GPU is being used**:
```python
print(f'Model device: {next(model.parameters()).device}')
# Should print: cuda:0
```

**If on CPU, check**:
1. CUDA module loaded: `module list`
2. PyTorch CUDA version matches: `python3 -c "import torch; print(torch.version.cuda)"`
3. GPU allocated: `nvidia-smi`

### Issue: DataLoader Num Workers Error

**Solution**: Reduce num_workers:
```python
NUM_WORKERS = 0  # Or 2
```

### Issue: File Not Found Errors

**Check paths are relative to notebook location**:
```python
DATA_DIR = Path('../data/processed/ga/lstm_data')  # Correct
# Not: Path('data/processed/ga/lstm_data')
```

### Issue: Job Killed by SLURM

**Increase memory allocation**:
```bash
#SBATCH --mem=64G  # Instead of 32G
```

---

## Expected Results

### Business LSTM (Atlanta Test Set)
- **Top-1 Accuracy**: 5-10% (challenging due to 20K businesses)
- **Top-5 Accuracy**: 15-25%
- **Top-10 Accuracy**: 25-35%
- **Top-20 Accuracy**: 35-45%

### Category LSTM (All Georgia)
- **Top-1 Accuracy**: 30-40% (easier, only 24 categories)
- **Top-3 Accuracy**: 50-60%
- **Top-5 Accuracy**: 60-70%

### Key Insight
The business model's test set is **Atlanta only** (never seen during training), ensuring:
- âœ… Zero data leakage
- âœ… True generalization from Georgia â†’ Atlanta
- âœ… Clean inference set for venue manager dashboard

---

## Next Steps After Training

1. **Analyze Results**: Review training curves and metrics
2. **Generate Predictions**: Use trained models on Atlanta test set
3. **Export for Visualization**: Convert predictions to JSON for dashboard
4. **Model Comparison**: Compare LSTM vs XGBoost performance
5. **Dashboard Integration**: Use predictions in Phase D visualization

---

## Support

For PACE-specific issues:
- **Documentation**: https://docs.pace.gatech.edu/
- **Help**: pace-support@oit.gatech.edu

For project-specific issues:
- Check training notebooks for inline documentation
- Review preprocessing documentation in `DATA_PREPROCESSING_DOCUMENTATION.md`
- Consult team members

---

## Quick Reference Commands

```bash
# Setup
ssh <username>@login-ice.pace.gatech.edu
salloc --gres=gpu:1 --mem=32G --time=4:00:00
module load cuda/11.8
source lstm_env/bin/activate

# Verify GPU
python3 -c "import torch; print(torch.cuda.is_available())"

# Train
jupyter lab --no-browser --port=8888

# Monitor
watch -n 1 nvidia-smi
tail -f logs/business_training.log

# Download results
scp -r <username>@login-ice:~/Forkast/models/ ./models/
```

---

**Good luck with training! ðŸš€**

